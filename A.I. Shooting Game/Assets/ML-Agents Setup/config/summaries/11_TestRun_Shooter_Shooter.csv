Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Curiosity Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Curiosity Reward,Is Training
1000,1.4189384,172.42857142857142,-0.27077854,-0.3656954,0.5207665532827377,0.5207665532827377,0.0,1.0
2000,1.4189386,195.8,-0.26862666,-0.38233015,0.41024993856747943,0.41024993856747943,0.0,1.0
3000,1.4189385,258.75,-0.28857023,-0.38221356,0.20583328045904636,0.20583328045904636,0.0,1.0
4000,1.4189386,261.6666666666667,-0.28816244,-0.37258267,0.5106664995352427,0.5106664995352427,0.0,1.0
5000,1.4189384,263.5,-0.27883825,-0.37845123,0.735208235681057,0.735208235681057,0.0,1.0
6000,1.4189385,298.75,-0.28491145,-0.37195402,0.6038748100399971,0.6038748100399971,0.0,1.0
7000,1.4189385,469.5,-0.28234988,-0.3715949,0.9409998431801796,0.9409998431801796,0.0,1.0
8000,1.4189385,267.6666666666667,-0.27753326,-0.36283734,0.11922214428583781,0.11922214428583781,0.0,1.0
9000,1.4189383,365.0,-0.2918629,-0.36730003,1.0214164331555367,1.0214164331555367,0.0,1.0
10000,1.4189385,272.5,-0.28285396,-0.3607369,0.5057498961687088,0.5057498961687088,0.0,1.0
11000,1.4189385,326.3333333333333,-0.27280235,-0.36699596,0.8215554356575012,0.8215554356575012,0.0,1.0
12000,1.4189383,311.0,-0.28090268,-0.36191356,0.37112492322921753,0.37112492322921753,0.0,1.0
13000,1.4189384,466.0,-0.27654234,-0.3710507,0.5505552887916565,0.5505552887916565,0.0,1.0
14000,1.4189385,705.0,-0.28979248,-0.37506253,0.05166652798652649,0.05166652798652649,0.0,1.0
15000,1.4189384,449.3333333333333,-0.27957365,-0.36090255,1.306166370709737,1.306166370709737,0.0,1.0
16000,1.4189385,735.0,-0.2852338,-0.38026452,3.0784990787506104,3.0784990787506104,0.0,1.0
17000,1.4189385,561.0,-0.28621793,-0.3638243,1.7243330478668213,1.7243330478668213,0.0,1.0
18000,1.4189386,599.0,-0.2965088,-0.37670273,1.0096662938594818,1.0096662938594818,0.0,1.0
